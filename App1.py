import streamlit as st
import os
from audio_recorder_streamlit import audio_recorder
from streamlit_float import *
from dotenv import load_dotenv
from Utils import generate_response,recognize_wav, text_to_speech2,get_answer_from_pdf, qa2,  autoplay_audio
import speech_recognition as sr
from Test import qabot

# Float feature initialization


r = sr.Recognizer()
float_init()
def initialize_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Welcome to our tourism virtual assistant using Vietnamemse! How can I assist you in planning your next adventure?"}
        ]
    # if "audio_initialized" not in st.session_state:
    #     st.session_state.audio_initialized = False

initialize_session_state()

st.title("Tourism Virtual Assistant ðŸ¤–")

# Create footer container for the microphone
footer_container = st.container()
with footer_container:
    audio_bytes = audio_recorder()

initialize_session_state()
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

if audio_bytes:
    # Write the audio bytes to a file
    with st.spinner("Transcribing..."):
        webm_file_path = "temp_audio.wav"
        with open(webm_file_path, "wb") as f:
            f.write(audio_bytes)

        transcript = recognize_wav(webm_file_path)
        if transcript:
            st.session_state.messages.append({"role": "user", "content": transcript})
            with st.chat_message("user"):
                st.write(transcript)
            os.remove(webm_file_path)

if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("ThinkingðŸ¤”..."):
            final_response = qabot(st.session_state.messages)
        with st.spinner("Generating audio response..."):
            audio_file = text_to_speech2(final_response)
            autoplay_audio(audio_file)
        st.write(final_response)
        st.session_state.messages.append({"role": "assistant", "content": final_response})
        os.remove(audio_file)

footer_container.float("bottom: 0rem;")
# Float the footer container and provide CSS to target it with